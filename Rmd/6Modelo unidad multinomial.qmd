---
title: "Estimación del empleo"
subtitle: "CEPAL - División de Estadísticas Sociales"
author: "Andrés Gutiérrez - Stalyn Guerrero"
format: html
project:
  type: website
  output-dir: docs
---

```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(printr)
```

# Introducción

En la estimación de áreas pequeñas, el modelo de muestreo captura la relación entre las estimaciones directa de la encuesta que siempre se acompaña de un error de estimación y el parámetro de interés que están tratando de estimar. Para los datos de empleo en la encuesta, el modelo de muestreo podría ser:

$$
Y_d \sim Multinon\left( \theta_{1d}, \theta_{2d},\theta_{3d} \right)
$$

con $d = 1,\cdots, D$ representa los dominios de interés. Los parámetros de interés $\theta_{1d}, \theta_{2d}$ y $\theta_{3d}$ representan la proporción de personas en algún estado laboral (Ocupado, Desocupado o Inactivo). Las estimaciones directas son representadas por $\hat{\theta}_{1d}, \hat{\theta}_{2d}$ y $\hat{\theta}_{3d}$ respectivamente.

## Modelo bayesiano

Para definir el modelo bayesiando debemos considerar una función de enlace para $\boldsymbol{\theta_d} = \left( \theta_{1d}, \theta_{2d},\theta_{3d} \right)$. Teniendo presente que la distribución multinomial es la generalización de la distribución binomial la función de enlace natural seria la transformación **logit**.

Esta función de enlace intenta capturar la relación entre $\boldsymbol{\theta_d}$ y cualquier información auxiliar que esté disponible. En este caso, se desea relacionar la condición de actividad económica (Ocupado, Desocupado e Inactivo) con el sexo, edad, años de estudio, etnia, departamento, área geográfica. También podemos utilizar variables auxiliares provenientes de registros administrativos o fuentes externas como la información satelital.

Dado que la variable de interés se puede modelar con la distribución Multinomial, con tres categorías.

$$
Y_{d} \sim  Multinon\left( \boldsymbol{\theta}_d \right)
$$

con $\sum_{k=1}^{3} \theta_i = 1$ al realizar la transformación logit es posible llegar a

$$
\begin{eqnarray*}
\theta_{1d} &=&  \frac{1}{1+ \exp\left( \mu_{1d} \right) + \exp\left( \mu_{2d} \right)}\\\\
\theta_{2d} &=&  \frac{\exp\left( \mu_{1d} \right)}{1+ \exp\left( \mu_{1d} \right) + \exp\left( \mu_{2d} \right)}\\\\
\theta_{3d} &=&  \frac{\exp\left( \mu_{2d} \right)}{1+ \exp\left( \mu_{1d} \right) + \exp\left( \mu_{2d} \right)}\\
\end{eqnarray*}
$$

Ahora es posible definir $\mu_{1d}$ y $\mu_{2d}$ como:

$$
\begin{eqnarray*}
\mu_{1d}&=&\boldsymbol{X}_d^{T}\boldsymbol{\beta_1}+u_{1d}\\
\mu_{2d}&=&\boldsymbol{X}_d^{T}\boldsymbol{\beta_2}+u_{2d}
\end{eqnarray*}
$$

para $u_{1d}\sim N\left(0,\sigma_{u}\right)$ y $u_{2d}\sim N\left(0,\sigma_{u}\right)$, siendo este el caso más simple. Para nuestro escenario se asume que $Cor\left(u_{1d},u_{2d} \right) \neq 0$ por tanto,  $\boldsymbol{u}_d = \left(u_{1d},u_{2d} \right) \sim N_2\left(0,\Sigma_{u}\right)$ bajo esta condiciones  la distribuciones previas estarían dadas por: 

$$
\begin{eqnarray*}
\boldsymbol{\beta}_k & \sim   & N(\mu_0, \tau^2_0)\\
\Sigma_{u} &\sim& Wishart\left( \Gamma_0, m_0 \right) 
\end{eqnarray*}
$$

A continuación se muestra el proceso realizado para la obtención de la predicción de la tasa de desocupación.

### Proceso de estimación en `R`

Las librerías utilizadas para desarrollar la metodología son las siguientes.

```{r}
rm(list =ls())
library(tidyverse)
library(bayesplot)
library(scales)
library(kableExtra)
library(patchwork)
library(cmdstanr)
library(printr)
```

Un conjunto de funciones desarrolladas para realizar de forma eficiente los procesos están consignadas en la siguiente rutina.

```{r}
source("0Funciones/funciones_mrp.R")
source("0Funciones/Funciones_empleo.R")
```

Entre las funciones incluidas en el archivo encuentra

-   **Indicadores_encuesta**: Realiza la estimación de las tasa de interés, de igual forma se tiene la función de *Indicadores_censo* para el calculo de los indicadores en el censo. Los indicadores son calculados como sigue:

    Tasa de participación:

    $$
    TP = \frac{Población\  económicamente\ activa}{Población\ en\ edad\ de\ trabajar}\times 100
    $$

    Tasa de ocupados

    $$
    TO = \frac{Población\ de\ ocupados}{Población\  en\  edad\  de trabajar}\times 100
    $$

    Tasa de desocupados

    $$
    TD = \frac{Población\  de\  desocupados}{Población\  económicamente \ activa}\times 100
    $$

### Importando datos

Los datos empleados en esta ocasión corresponden a la ultima encuesta de hogares, la cual ha sido estandarizada por *CEPAL* y se encuentra disponible en *BADEHOG*. Se filtran las personas con una edad mayor a los 15 años en el censo y la encuesta.

En interés se centra en la estimación de la Tasa de ocupados, Tasa de desocupados y Tasa de Participación. La variable respuesta es **la condición de actividad económica**, la cual se identifica en la base de datos como **empleo** y toma los valores de: 

-   Niño = **-1**

-   Ocupado = **1**

-   Desocupado = **2**

-   Inactiva = **3** y

-   No sabe, no responde = **9**

El proceso se simplifica al considerar solo tres estados ocupados, desocupados e inactivos.

```{r}
encuesta_mrp <-  readRDS("../Data/encuestaURY20N_Montevideo.rds") %>% 
  filter(edad > 13, condact3 %in% 1:3)  %>%
  transmute(
  depto = "MONTEVIDEO",
  mpio = str_pad(
    string = secc,
    pad = "1",
    width = 3
  ),
  mpio = str_pad(
    string = mpio,
    pad = "0",
    width = 4
  ),
 segm = paste0(mpio,segm),
  empleo = condact3,

  area = case_when(areageo2 == 1 ~ "1", TRUE ~ "0"),
  sexo = as.character(sexo),
  anoest = case_when(
    edad < 5 | anoest == -1   ~ "98"  ,    #No aplica
    anoest < 1  ~ "1",     # Sin educación
    anoest <= 6 ~ "2",   # 1 - 6
    anoest <= 12 ~ "3",     # 7 - 12
    anoest > 12 ~ "4",    # mas de 12
    anoest == 99 ~ "99",     #NS/NR ##### valida con cuidado
    TRUE ~ "Error"
  ),
  
  edad = case_when(edad < 15 ~ "1",
                   edad < 30 ~ "2",
                   edad < 45 ~ "3",
                   edad < 65 ~ "4",
                   TRUE ~ "5"),
  
  etnia = case_when(etnia_ee == 1 ~ "1", # Indígena
                    etnia_ee  == 2 ~ "2", # afro negro mulato
                    TRUE ~ "3"),  # Otro  
  fep = `_fep`
) 

```

```{r, echo=FALSE}
kable(encuesta_mrp %>% 
  head(10),
      format = "html", digits =  4,
      caption = "Encuesta estandarizada") %>% 
    kable_classic()

```

La base del censo fue estandarizado previamente, por tanto, se debe realizar la lectura del archivo estandarizado y excluir a los niños.

```{r}
censo_mrp <- readRDS("../Data/censo_Montevideo.rds") %>% 
  filter(edad != "1")
```

```{r, echo=FALSE}
kable(censo_mrp %>% arrange(desc(n)) %>% 
  head(10),
      format = "html", digits =  4,
      caption = "Censo estandarizado") %>% 
    kable_classic()

```

La información auxiliar disponible fue extraída del censo (tasa de desocupación) e imágenes satelitales (luces nocturnas, uso del suelo urbano y uso del suelo cultivos)

```{r}
statelevel_predictors_df <- readRDS("../Data/statelevel_predictors_segm.rds")
```

```{r, echo=FALSE}
kable(statelevel_predictors_df %>% 
  head(10),
      format = "html", digits =  4,
      caption = "Información auxiliar") %>% 
    kable_classic()

```

-   *tasa_desocupacion*: Información extraída del último censo del país.
-   *F182013_stable_lights*, *X2016_crops.coverfraction* y *X2016_urban.coverfraction* información satelital extraída de google earth engine.

### Programando el Modelo en `STAN`

El modelo escrito en `STAN` queda con la siguiente estructura.

```{r, eval=FALSE}
 // La función pred_theta es definida para realizar el calculo de las predicciones. 
functions {
  matrix pred_theta(matrix Xp, matrix Zp, int p, matrix beta, matrix u){
     // Xp: Matriz de efectos fijos
     // Zp: Matriz de efectos aleatorios
     // p: Número de categorías de Y.
     // beta: Matriz de coeficientes de los efectos fijos 
     // u: Matriz de coeficiente de los efectos aleatorios. 
  
  int D1 = rows(Xp);
  real num1[D1, p];
  real den1[D1];
  matrix[D1,p] theta_p;
  
  for(d in 1:D1){
    num1[d, 1] = 1;
    num1[d, 2] = exp(Xp[d, ] * beta[1, ]' + Zp[d, ] * u[1, ]') ;
    num1[d, 3] = exp(Xp[d, ] * beta[2, ]' + Zp[d, ] * u[2, ]') ;
    
    den1[d] = sum(num1[d, ]);
  }
  
  for(d in 1:D1){
    for(i in 2:p){
    theta_p[d, i] = num1[d, i]/den1[d];
    }
    theta_p[d, 1] = 1/den1[d];
   }

  return theta_p  ;
  }
  
}

data {
  int<lower=1> D;    // número de postestrto 
  int<lower=1> D1;   // número de dominios por predecir 
  int<lower=1> P;    // categorías
  int<lower=1> K;    // cantidad de regresores
  int<lower=1> Kz;   // cantidad de regresores en Z
  int y[D, P];       // matriz de datos
  matrix[D, K] X;    // matriz de covariables
  matrix[D, Kz] Z;   // matriz de covariables
  matrix[D1, K] Xp;  // matriz de covariables
  matrix[D1, Kz] Zp; // matriz de covariables
}
  

parameters {
  matrix[P-1, K] beta;// matriz de parámetros 
  vector<lower=0>[P-1] sigma_u;       // random effects standard deviations
  // declare L_u to be the Choleski factor of a 2x2 correlation matrix
  cholesky_factor_corr[P-1] L_u;
  matrix[P-1, Kz] z_u;                  
}

transformed parameters {
  simplex[P] theta[D];// vector de parámetros;
  real num[D, P];
  real den[D];
  // this transform random effects so that they have the correlation
  // matrix specified by the correlation matrix above
  matrix[P-1, Kz] u; // random effect matrix
  u = diag_pre_multiply(sigma_u, L_u) * z_u;
  
  for(d in 1:D){
    num[d, 1] = 1;
    num[d, 2] = exp(X[d, ] * beta[1, ]' + Z[d, ] * u[1, ]') ;
    num[d, 3] = exp(X[d, ] * beta[2, ]' + Z[d, ] * u[2, ]') ;
    
    den[d] = sum(num[d, ]);

  }
  for(d in 1:D){
    for(p in 2:P){
    theta[d, p] = num[d, p]/den[d];
    }
    theta[d, 1] = 1/den[d];
  }
}

model {
  L_u ~ lkj_corr_cholesky(1); // LKJ prior for the correlation matrix
  to_vector(z_u) ~ normal(0, 1);
  sigma_u ~ cauchy(0, 50);
  to_vector(beta) ~ normal(0, 100);
 
  for(d in 1:D){
    target += multinomial_lpmf(y[d, ] | theta[d, ]); 
  }
}

  
generated quantities {
  // predict 
  matrix[D1,P] theta_p;// vector de parámetros;
  matrix[2, 2] Omega;
  vector<lower=0>[2] sdcomprobar;
  sdcomprobar[1] = sd(u[1, ]);
  sdcomprobar[2] = sd(u[2, ]);

  Omega = L_u * L_u'; // so that it return the correlation matrix
// predicción 

theta_p = pred_theta(Xp,Zp,P, beta, u) ; 

}

```

La compilación del modelo se ejecuta con `cmdstan_model`

```{r}
fit <-
  cmdstan_model(
    stan_file = "../Data/modelosStan/Multinivel_multinomial.stan",
    compile = TRUE)
```

### Niveles de agregación para colapsar encuesta

La estimación del modelo multinomial se realiza mediante el conteo del número de éxitos en cada categoría, es decir, dadas las variables $X$ cuantas personas de la encuestas están en cada uno de los estados. Para lograr hacer el conteo identificamos las variables de agregación.

```{r}
byAgrega <- c("depto",  "mpio",   "segm"  ,
              "empleo", "area",   "sexo",  
              "anoest", "edad", "etnia")
  
```

### Creando base con la encuesta agregada

El resultado de agregar la base de dato se muestra a continuación:

```{r}
encuesta_df_agg <-
  encuesta_mrp %>%
  group_by_at(all_of(byAgrega)) %>%
  summarise(n = n(),
            .groups = "drop")
```

Después de agregar la base se ordenan las categorías en las columnas así como se muestra a continuación.

```{r}
encuesta_df_agg %<>%
  spread(key = "empleo",
         value = "n", sep = "_" ,fill = 0) %>% 
  arrange(desc(empleo_1))
```

```{r, echo=FALSE}
kable(encuesta_df_agg %>% 
  head(10),
      format = "html", digits =  4,
      caption = "Encuesta agregada") %>% 
    kable_classic()

```

por último, incorporamos la información proveniente de otras fuentes.

```{r}
encuesta_df_agg <- inner_join(encuesta_df_agg, 
                              statelevel_predictors_df)


```

Dado que `STAN` permite hacer las predicciones de forma inmediata, debemos incluir la información auxiliar a la base del censo.

```{r}
censo_df <- inner_join(censo_mrp, 
                       statelevel_predictors_df) %>% 
  ungroup()

```

### Parámetros del modelo

Los parámetros son incluidos en una lista, definiendo cada argumento por separado:

-   $Y$ Matriz de con los conteos para cada categoría.

```{r}
Y <- encuesta_df_agg %>% select(matches("empleo")) %>%
  as.matrix(.)
```

-   $X$ Matriz con los efectos fijos en la encuesta:

```{r}
model_fijo  <- formula(~ -1 + sexo + 
                         anoest + 
                         edad + 
                         etnia + 
                         tasa_desocupacion +
                         F182013_stable_lights +
                         X2016_urban.coverfraction)
X <- encuesta_df_agg %>% 
  model.matrix(model_fijo, data = .)  
```

-   $Z$ Matriz con los efectos aleatorios en la encuesta:

```{r}
Z <- encuesta_df_agg %>% select(matches("segm")) %>%
  model.matrix( ~ -1+ ., data = .)%>%
  as.matrix(.)
```

-   $Xp$ Matriz con los efectos fijos en el censo:

```{r}
Xp <- censo_df %>%
  model.matrix(model_fijo, data = .)  
```

-   $Zp$ Matriz con los efectos aleatorios en el censo:

```{r}
Zp <- censo_df %>% select(matches("segm")) %>%
  model.matrix( ~ -1+ ., data = .)%>%
  as.matrix(.)

```

## Validando X y Xp

Dado que el código escrito para `STAN` NO realiza la validación de variables como lo hace `R`, es necesario realizar esas validaciones de forma externa al programa. En este caso, identifican las columnas comunes entre los efectos fijos $X$ y $Xp$ y los efectos aleatorios $Z$ y $Zp$, en caso de identificar diferencias, están deben ser introducidas de forma manual a $Xp$ y $Zp$.

```{r}
# Lista de elementos presentes en X pero no en Xp
# setdiff(colnames(X) ,colnames(Xp))

if(length(setdiff(colnames(X) ,colnames(Xp)))>0){
  agregarXp  <- setdiff(colnames(X) ,colnames(Xp))
  temp <- matrix(0, nrow = nrow(Xp),
                 ncol = length(agregarXp),
                 dimnames = list(1:nrow(Xp), agregarXp))
  
  Xp <- cbind(Xp, temp)  
}

```

## Validando Z y Zp

```{r}
# Lista de elementos presentes en Z pero no en Zp
# setdiff(colnames(Z) ,colnames(Zp))

if(length(setdiff(colnames(Z) ,colnames(Zp)))>0){
  agregarZp  <- setdiff(colnames(Z) ,colnames(Zp))
  temp <- matrix(0, nrow = nrow(Zp),
                 ncol = length(agregarZp),
                 dimnames = list(1:nrow(Zp), agregarZp))
  
  Zp <- cbind(Zp, temp)  
}

```

Ahora debe seleccionar las variables del censo ($Xp$,$Zp$) en el mismo orden que aparecen en la encuesta $X$ y $Z$.

```{r}
xnames <-  colnames(X)
Znames <-  colnames(Z)
```

### Creando la información para el modelo

La forma de introducir los datos en `STAN` es mediante un objeto tipo lista de `R`, la cual se construye de la siguiente forma:   

```{r, eval=TRUE}
sample_data <- list(D = nrow(encuesta_df_agg), # Número de dominios. 
                    P = ncol(Y),               # Número de estados.
                    K = ncol(X[,xnames]),      # Número de efecto fijo.
                    D1 = nrow(Xp),             # Número de dominios a predecir. 
                    Kz = ncol(Z),              # Número de efectos aleatorios.
                    Z = Z[,Znames],            # Matriz de efectos aleatorios.
                    Zp = Zp[,Znames],          # Matriz de efectos aleatorios.
                    y = Y,                     # Conteos por categorías. 
                    X = X[,xnames],            # Matriz de efecto fijo 
                    Xp = Xp[,xnames]           # Matriz de efecto fijo
)
```

El modelo se compila con la siguiente instrucción,  `el tiempo de ejecución fue de aproximadamente 3 días`.

```{r, eval=FALSE}
fit_mcmc <- fit$sample(
  num_samples = 200,
  num_warmup = 200,
  data = sample_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4
)
```

Después de obtener el resultado, se exportan con la sintaxis

```{r, eval=FALSE}
fit_mcmc$save_object(
  file = "../Data/fit_multinomial.rds")

```

# Proceso de estimación y predicción

La lectura del modelo resultante se hace de la forma habitual.

```{r}
fit <- readRDS("../Data/fit_multinomial.rds")
```

Es posible revisar de forma visual el comportamiento de las cadenas con las funciones `mcmc_dens_chains`, `mcmc_areas` y `mcmc_trace`. Dado el número de realizaciones aleatoria que se hicieron para cada cadena no observaremos un comportamiento estable de la misma.

```{r,eval=FALSE}
library(bayesplot)
mcmc_dens_chains(fit$draws(variables = "beta"))
mcmc_areas(fit$draws("beta")) 
mcmc_trace(fit$draws("beta")) 
```

### Predicción en el censo

Después de realizar validaciones sobre las predicciones obtenidas con el modelo, podemos pasar hacer las estimaciones para todos los dominios.

```{r}
poststrat_df <- readRDS("../Data/poststrat_multinomial.RDS") 
```

```{r, echo=FALSE}
kable(poststrat_df %>% 
  head(10),
      format = "html", digits =  4,
      caption = "Predicción en el censo") %>% 
    kable_classic()

```

Realizar la predicción de los indicadores de interés.

```{r}
Indicadores_mpio <- Indicadores_censo(setdata = poststrat_df, "mpio")
```

```{r, echo=FALSE}
kable(Indicadores_mpio,
      format = "html", digits =  4,
      caption = "Estimación para mpio") %>% 
    kable_classic()

```

### Creando el mapa con los resultados.

Por último se construye un mapa con los resultados obtenidos.

```{r}
library(sp)
library(sf)
library(tmap)

brks_TO <- c(0 ,20, 40, 60, 80,100)
brks_TD <- c(0,5, 10, 15, 20, 100)
brks_TP <- c(0 ,20, 40, 60, 80,100)

## Leer Shapefile del país
ShapeSAE <- read_sf("../Shape/secc_hog11.shp")%>% 
  filter(nombdepto == "MONTEVIDEO") %>% 
  mutate(mpio = str_pad(codsec,width = 4,pad = "0"))

mapa <- tm_shape(ShapeSAE %>%
                           left_join(Indicadores_mpio,  by = "mpio"))


Mapa_lp <-
  mapa + tm_polygons(
    c("TD"),
    breaks = brks_TD,
    title = "Tasa de desocupación",
    palette = "YlOrRd",
    colorNA = "white"
  ) + tm_layout(asp = 0)

Mapa_lp

```

Con los resultados obtenidos podemos tener predicción sobre los segmento no observados.

```{r}
Indicadores_segm <- Indicadores_censo(setdata = poststrat_df, "segm")
```

```{r, echo=FALSE}
kable(Indicadores_segm %>% head(20),
      format = "html", digits =  4,
      caption = "Estimación para segmento") %>% 
    kable_classic()

```

```{r, echo=FALSE}
## Leer Shapefile del país
ShapeSAE <- read_sf("../Shape/ine_seg_11.shp") %>% 
  filter(nombdepto == "MONTEVIDEO") %>% 
  mutate(mpio = str_pad(codsec,width = 4,pad = "0"),
         segm = str_pad(codseg,width = 7,pad = "0"))

mapa <- tm_shape(ShapeSAE %>%
                           left_join(Indicadores_segm,  by = "segm"))


Mapa_lp <-
  mapa + tm_polygons(
    c("TD"),
    breaks = brks_TD,
    title = "Tasa de desocupación",
    palette = "YlOrRd",
    colorNA = "white"
  ) + tm_layout(asp = 0)

Mapa_lp2 <-
  mapa + tm_polygons(
    c("TO"),
    breaks = brks_TO,
    title = "Tasa de ocupación",
    palette = "-YlOrRd",
    colorNA = "white"
  ) + tm_layout(asp = 0)

Mapa_lp2
Mapa_lp
```
